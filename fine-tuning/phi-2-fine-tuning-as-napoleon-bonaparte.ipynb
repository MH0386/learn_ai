{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8155794,"sourceType":"datasetVersion","datasetId":4364211}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mh0386/phi-2-fine-tuning-as-napoleon-bonaparte?scriptVersionId=221951540\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nos.environ[\"CONDA_PREFIX\"] = '/opt/conda'\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\nos.environ[\"WANDB_PROJECT\"] = \"Chatacter\"\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\nos.environ[\"WANDB_WATCH\"] = \"all\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:16:17.859963Z","iopub.execute_input":"2024-04-18T18:16:17.86089Z","iopub.status.idle":"2024-04-18T18:16:17.867369Z","shell.execute_reply.started":"2024-04-18T18:16:17.860848Z","shell.execute_reply":"2024-04-18T18:16:17.86597Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U -q uv pip\n!uv pip install \\\n        wandb \\\n        loralib \\\n        peft \\\n        huggingface_hub \\\n        trl \\\n        datasets \\\n        transformers \\\n        bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:16:17.86938Z","iopub.execute_input":"2024-04-18T18:16:17.869714Z","iopub.status.idle":"2024-04-18T18:16:37.190223Z","shell.execute_reply.started":"2024-04-18T18:16:17.869682Z","shell.execute_reply":"2024-04-18T18:16:37.189026Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from dataclasses import dataclass, field\nfrom pprint import pprint\nfrom typing import Optional\nimport huggingface_hub as hf_hub\nimport torch\nimport wandb\nfrom datetime import datetime, timedelta, timezone\nfrom datasets import load_dataset\nfrom peft import (\n    LoraConfig,\n    PeftConfig,\n    PeftModel,\n    get_peft_model,\n    prepare_model_for_kbit_training,\n)\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    AutoConfig,\n    DataCollatorForLanguageModeling,\n    Trainer,\n)\nfrom trl import SFTTrainer\nfrom kaggle_secrets import UserSecretsClient","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T18:16:37.192327Z","iopub.execute_input":"2024-04-18T18:16:37.192705Z","iopub.status.idle":"2024-04-18T18:16:46.382546Z","shell.execute_reply.started":"2024-04-18T18:16:37.192671Z","shell.execute_reply":"2024-04-18T18:16:46.381437Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git config --global credential.helper store\nhf_hub.login(token=UserSecretsClient().get_secret(\"hf\"), add_to_git_credential=True)\nwandb.login(key=UserSecretsClient().get_secret(\"wandb\"))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-18T18:16:46.383819Z","iopub.execute_input":"2024-04-18T18:16:46.384727Z","iopub.status.idle":"2024-04-18T18:16:50.116201Z","shell.execute_reply.started":"2024-04-18T18:16:46.384693Z","shell.execute_reply":"2024-04-18T18:16:50.114847Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@dataclass\nclass ScriptArguments:\n    \"\"\"\n    These arguments vary depending on how many GPUs you have, what their capacity and features are, and what size model you want to train.\n    \"\"\"\n    per_device_train_batch_size: Optional[int] = field(default=8)\n#     per_device_eval_batch_size: Optional[int] = field(default=1)\n    auto_find_batch_size: Optional[bool] = field(default=True)\n    gradient_accumulation_steps: Optional[int] = field(default=4)\n    learning_rate: Optional[float] = field(default=2e-4)\n    max_grad_norm: Optional[float] = field(default=0.3)\n    weight_decay: Optional[int] = field(default=0.001)\n    lora_alpha: Optional[int] = field(default=32)\n    lora_dropout: Optional[float] = field(default=0.05)\n    lora_r: Optional[int] = field(default=16) \n    max_seq_length: Optional[int] = field(default=None) \n    model_name: Optional[str] = field(default=\"microsoft/phi-2\")\n    dataset_name: Optional[str] = field(default=\"MH0386/napoleon_bonaparte\")\n    hf_username: Optional[str] = field(default=\"MH0386\")\n    fp16: Optional[bool] = field(default=True)\n    bf16: Optional[bool] = field(default=True)\n    packing: Optional[bool] = field(default=False, metadata={\"help\": \"Use packing dataset creating.\"})\n    gradient_checkpointing: Optional[bool] = field(default=True, metadata={\"help\": \"Enables gradient checkpointing.\"})\n    use_flash_attention_2: Optional[bool] = field(default=True, metadata={\"help\": \"Enables Flash Attention 2.\"})\n    optim: Optional[str] = field(default=\"paged_adamw_8bit\", metadata={\"help\": \"The optimizer to use.\"})\n    lr_scheduler_type: str = field(\n        default=\"linear\", #constant\n        metadata={\"help\": \"Learning rate schedule. Constant a bit better than cosine, and has advantage for analysis\"},\n    )\n    max_steps: int = field(default=1000, metadata={\"help\": \"How many optimizer update steps to take\"})\n    warmup_ratio: float = field(default=0.05, metadata={\"help\": \"Fraction of steps to do a warmup for\"})\n    save_steps: int = field(default=100, metadata={\"help\": \"Save checkpoint every X updates steps.\"})\n    logging_steps: int = field(default=1, metadata={\"help\": \"Log every X updates steps.\"})\n    output_dir: str = field(\n        default=\"MH0386/phi-2-napoleon-bonaparte\",\n        metadata={\"help\": \"The output directory where the model predictions and checkpoints will be written.\"},\n    )","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:16:50.119618Z","iopub.execute_input":"2024-04-18T18:16:50.120494Z","iopub.status.idle":"2024-04-18T18:16:50.137386Z","shell.execute_reply.started":"2024-04-18T18:16:50.120435Z","shell.execute_reply":"2024-04-18T18:16:50.136242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"parser = HfArgumentParser(ScriptArguments)\nscript_args = parser.parse_args_into_dataclasses(return_remaining_strings=True)[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:16:50.138862Z","iopub.execute_input":"2024-04-18T18:16:50.139307Z","iopub.status.idle":"2024-04-18T18:16:50.160426Z","shell.execute_reply.started":"2024-04-18T18:16:50.139263Z","shell.execute_reply":"2024-04-18T18:16:50.159274Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pprint(script_args)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:16:50.161882Z","iopub.execute_input":"2024-04-18T18:16:50.162301Z","iopub.status.idle":"2024-04-18T18:16:50.176349Z","shell.execute_reply.started":"2024-04-18T18:16:50.162263Z","shell.execute_reply":"2024-04-18T18:16:50.175353Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def formatting_func(example):\n    full_prompt = f\"Instruct: {example['Q']}\\nOutput: {example['A']}\"\n    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n    return tokenized_full_prompt","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:16:50.177855Z","iopub.execute_input":"2024-04-18T18:16:50.178783Z","iopub.status.idle":"2024-04-18T18:16:50.191853Z","shell.execute_reply.started":"2024-04-18T18:16:50.178749Z","shell.execute_reply":"2024-04-18T18:16:50.190828Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type=\"nf4\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:16:50.193495Z","iopub.execute_input":"2024-04-18T18:16:50.193821Z","iopub.status.idle":"2024-04-18T18:16:50.207216Z","shell.execute_reply.started":"2024-04-18T18:16:50.193793Z","shell.execute_reply":"2024-04-18T18:16:50.206274Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    script_args.model_name, \n    quantization_config=quantization_config,\n    device_map=\"auto\",\n#     attn_implementation=\"sdpa\" if not script_args.use_flash_attention_2 else \"flash_attention_2\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:17:20.270058Z","iopub.execute_input":"2024-04-18T18:17:20.270462Z","iopub.status.idle":"2024-04-18T18:17:54.117704Z","shell.execute_reply.started":"2024-04-18T18:17:20.270434Z","shell.execute_reply":"2024-04-18T18:17:54.116712Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:17:54.119493Z","iopub.execute_input":"2024-04-18T18:17:54.119849Z","iopub.status.idle":"2024-04-18T18:17:54.124817Z","shell.execute_reply.started":"2024-04-18T18:17:54.119818Z","shell.execute_reply":"2024-04-18T18:17:54.123787Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(script_args.model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.padding_side = 'right'\ntokenizer.add_eos_token = True","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:17:59.313406Z","iopub.execute_input":"2024-04-18T18:17:59.313813Z","iopub.status.idle":"2024-04-18T18:18:04.910946Z","shell.execute_reply.started":"2024-04-18T18:17:59.313781Z","shell.execute_reply":"2024-04-18T18:18:04.909834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=script_args.lora_r,\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n        \"lm_head\",\n    ],\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    lora_alpha=script_args.lora_alpha,\n    lora_dropout=script_args.lora_dropout\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:04.913015Z","iopub.execute_input":"2024-04-18T18:18:04.913399Z","iopub.status.idle":"2024-04-18T18:18:04.919743Z","shell.execute_reply.started":"2024-04-18T18:18:04.913367Z","shell.execute_reply":"2024-04-18T18:18:04.918446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:04.921151Z","iopub.execute_input":"2024-04-18T18:18:04.921528Z","iopub.status.idle":"2024-04-18T18:18:05.280376Z","shell.execute_reply.started":"2024-04-18T18:18:04.921489Z","shell.execute_reply":"2024-04-18T18:18:05.279275Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.add_adapter(peft_config=lora_config, adapter_name=\"adapter_1\")\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:05.283502Z","iopub.execute_input":"2024-04-18T18:18:05.284263Z","iopub.status.idle":"2024-04-18T18:18:05.55061Z","shell.execute_reply.started":"2024-04-18T18:18:05.284229Z","shell.execute_reply":"2024-04-18T18:18:05.54948Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"train_dataset = load_dataset(script_args.dataset_name)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:05.551943Z","iopub.execute_input":"2024-04-18T18:18:05.552294Z","iopub.status.idle":"2024-04-18T18:18:08.262259Z","shell.execute_reply.started":"2024-04-18T18:18:05.552265Z","shell.execute_reply":"2024-04-18T18:18:08.261294Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:08.263634Z","iopub.execute_input":"2024-04-18T18:18:08.264019Z","iopub.status.idle":"2024-04-18T18:18:08.271438Z","shell.execute_reply.started":"2024-04-18T18:18:08.263982Z","shell.execute_reply":"2024-04-18T18:18:08.270412Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset_maped = train_dataset[\"train\"].shuffle().map(formatting_func)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:08.272783Z","iopub.execute_input":"2024-04-18T18:18:08.273155Z","iopub.status.idle":"2024-04-18T18:18:12.674678Z","shell.execute_reply.started":"2024-04-18T18:18:08.273123Z","shell.execute_reply":"2024-04-18T18:18:12.673618Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset_maped","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:12.67626Z","iopub.execute_input":"2024-04-18T18:18:12.676674Z","iopub.status.idle":"2024-04-18T18:18:12.683997Z","shell.execute_reply.started":"2024-04-18T18:18:12.676634Z","shell.execute_reply":"2024-04-18T18:18:12.683086Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if torch.cuda.device_count() > 1: # If more than 1 GPU\n    model.is_parallelizable = True\n    model.model_parallel = True","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:12.687308Z","iopub.execute_input":"2024-04-18T18:18:12.687856Z","iopub.status.idle":"2024-04-18T18:18:13.69352Z","shell.execute_reply.started":"2024-04-18T18:18:12.687821Z","shell.execute_reply":"2024-04-18T18:18:13.692365Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:13.695Z","iopub.execute_input":"2024-04-18T18:18:13.695375Z","iopub.status.idle":"2024-04-18T18:18:13.706935Z","shell.execute_reply.started":"2024-04-18T18:18:13.695342Z","shell.execute_reply":"2024-04-18T18:18:13.705975Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:13.708966Z","iopub.execute_input":"2024-04-18T18:18:13.709382Z","iopub.status.idle":"2024-04-18T18:18:13.722167Z","shell.execute_reply.started":"2024-04-18T18:18:13.709333Z","shell.execute_reply":"2024-04-18T18:18:13.721049Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=script_args.output_dir,\n    per_device_train_batch_size=script_args.per_device_train_batch_size,\n    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n    optim=script_args.optim,\n    save_steps=script_args.save_steps,\n    logging_steps=script_args.logging_steps,\n    learning_rate=script_args.learning_rate,\n    max_grad_norm=script_args.max_grad_norm,\n    max_steps=script_args.max_steps,\n    warmup_ratio=script_args.warmup_ratio,\n    lr_scheduler_type=script_args.lr_scheduler_type,\n    gradient_checkpointing=script_args.gradient_checkpointing,\n    fp16=script_args.fp16,\n#     bf16=script_args.bf16,\n    num_train_epochs=1,\n#     evaluation_strategy=\"steps\",\n    report_to=\"wandb\",\n    run_name=f\"phi-2-napoleon-{datetime.now(timezone(timedelta(hours=2))).strftime('%Y-%m-%d-%H-%M')}\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:19:06.054707Z","iopub.execute_input":"2024-04-18T18:19:06.055144Z","iopub.status.idle":"2024-04-18T18:19:06.262695Z","shell.execute_reply.started":"2024-04-18T18:19:06.055108Z","shell.execute_reply":"2024-04-18T18:19:06.261381Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_dataset_maped,\n    tokenizer=tokenizer,\n    data_collator=collator,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:18:46.517687Z","iopub.execute_input":"2024-04-18T18:18:46.51809Z","iopub.status.idle":"2024-04-18T18:18:46.537904Z","shell.execute_reply.started":"2024-04-18T18:18:46.518059Z","shell.execute_reply":"2024-04-18T18:18:46.53689Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:17:56.441168Z","iopub.status.idle":"2024-04-18T18:17:56.441731Z","shell.execute_reply.started":"2024-04-18T18:17:56.441437Z","shell.execute_reply":"2024-04-18T18:17:56.44146Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:17:56.443282Z","iopub.status.idle":"2024-04-18T18:17:56.44369Z","shell.execute_reply.started":"2024-04-18T18:17:56.443489Z","shell.execute_reply":"2024-04-18T18:17:56.443506Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.model.save_pretrained(script_args.output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:17:56.445003Z","iopub.status.idle":"2024-04-18T18:17:56.445583Z","shell.execute_reply.started":"2024-04-18T18:17:56.445297Z","shell.execute_reply":"2024-04-18T18:17:56.44532Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T18:17:56.44724Z","iopub.status.idle":"2024-04-18T18:17:56.448055Z","shell.execute_reply.started":"2024-04-18T18:17:56.447494Z","shell.execute_reply":"2024-04-18T18:17:56.447517Z"},"trusted":true},"outputs":[],"execution_count":null}]}