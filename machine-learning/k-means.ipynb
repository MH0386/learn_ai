{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport cv2\nimport numpy as np\nfrom keras.datasets import mnist\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt","metadata":{"id":"5aDVwFVZiIkA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_BLOCKS = 9\nblock_size = int(27 / np.sqrt(NUM_BLOCKS))","metadata":{"id":"JGkK08mzpa3y","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_centroid(block):\n    \"\"\"Calculate the centroid of a 2D matrix\"\"\"\n    rows, cols = block.shape\n    x_centroid = 0.0\n    y_centroid = 0.0\n    for i in range(rows):\n        for j in range(cols):\n            x_centroid += i * block[i, j]\n            y_centroid += j * block[i, j]\n    total = np.sum(block)\n    x_centroid = x_centroid / total\n    y_centroid = y_centroid / total\n    return x_centroid, y_centroid","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_chain_code(image):\n    image = np.dstack([image, image, image])\n    img = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    _, img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n    row, col = img_bin.shape\n    if np.all(img_bin == 0):\n        img_bin[np.random.randint(0, row, 2), np.random.randint(0, col, 2)] = 255\n    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    chain_code = []\n    point = contours[0][0][0]\n    for i in range(1, len(contours[0])):\n        next_point = contours[0][i][0]\n        diff = next_point - point\n        if diff[0] == 0 and diff[1] == 1:\n            chain_code.append(6) \n        elif diff[0] == -1 and diff[1] == 1:\n            chain_code.append(5) \n        elif diff[0] == -1 and diff[1] == 0:\n            chain_code.append(4)\n        elif diff[0] == -1 and diff[1] == -1:\n            chain_code.append(3)\n        elif diff[0] == 0 and diff[1] == -1:\n            chain_code.append(2)\n        elif diff[0] == 1 and diff[1] == -1:\n            chain_code.append(1)\n        elif diff[0] == 1 and diff[1] == 0:\n            chain_code.append(0)\n        elif diff[0] == 1 and diff[1] == 1:\n            chain_code.append(7)\n        point = next_point\n    return chain_code","metadata":{"id":"zvnrc-GKpgnH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features_with_chain_code(image):\n    features = np.zeros((block_size, block_size, 50))\n    for i in range(0, 27, block_size):\n        for j in range(0, 27, block_size):\n            block = image[i : i + block_size, j : j + block_size]\n            chain_code = generate_chain_code(block)\n            # print(\"chain len\", len(chain_code))\n            if len(chain_code) < 50:\n                chain_code += [0] * (50 - len(chain_code))\n            # print(\"chain\", chain_code)\n            features[i // block_size, j // block_size] = chain_code\n    return features","metadata":{"id":"LZeAI758pie6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features_with_centroid(image):\n    features = np.zeros((block_size, block_size, 2))\n    for i in range(0, 28, block_size):\n        for j in range(0, 28, block_size):\n            block = image[i : i + block_size, j : j + block_size]\n            x_centroid, y_centroid = calculate_centroid(block)\n            features[int(i / block_size), int(j / block_size), 0] = x_centroid\n            features[int(i / block_size), int(j / block_size), 1] = y_centroid\n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def k_means(X, k=10, max_iters=sys.maxsize):\n    centroids = X[np.random.choice(range(X.shape[0]), size=k, replace=False)]\n    for _ in range(max_iters):\n        labels = np.argmin(np.linalg.norm(X[:, np.newaxis] - centroids, axis=-1), axis=-1)\n        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n        if np.all(centroids == new_centroids): break\n        centroids = new_centroids\n    return centroids, labels","metadata":{"id":"YpFYrRAkiIkB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train = x_train[:, 1:28, 1:28]\nx_test = x_test[:, 1:28, 1:28]\ny_train = y_train.astype(np.int64)\ny_test = y_test.astype(np.int64)","metadata":{"id":"g5kfxIRZiIkB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = OneHotEncoder()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train.shape, y_train.shape","metadata":{"id":"WJYsJD3tkxFQ","outputId":"37c5c244-3825-405a-9ccd-23d0722c2627","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, shuffle=True)","metadata":{"id":"8pVNQqejiIkB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train.shape, y_train.shape","metadata":{"id":"WJYsJD3tkxFQ","outputId":"37c5c244-3825-405a-9ccd-23d0722c2627","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using Chain Code","metadata":{}},{"cell_type":"code","source":"train_features_with_chain_code = np.nan_to_num(np.array([extract_features_with_chain_code(image) for image in x_train]))","metadata":{"id":"hYathqMzproz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features_with_chain_code.shape","metadata":{"id":"2DUg2_4ZptNw","outputId":"8a4d519f-b361-43df-a04b-5967cf3b96f4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features_with_chain_code = train_features_with_chain_code.reshape(train_features_with_chain_code.shape[0], -1)","metadata":{"id":"REb8BaT5pvuk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features_with_chain_code.shape","metadata":{"id":"eqWlfd0brZyQ","outputId":"966cd866-6ce4-4b9b-bd92-6cf06519b401","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"centroids, labels = k_means(train_features_with_chain_code)","metadata":{"id":"wLRyzjDsmU6q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"centroids.shape, labels.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = encoder.fit_transform(labels.reshape(-1, 1)).toarray()\ny_train = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_score(y_train, labels)","metadata":{"id":"cieQ0_ZHiIkB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best = KMeans(n_clusters=10)\naccuracies = np.array([])\nmax_acc = 0\nfor _ in range(10):\n    kmeans = KMeans(n_clusters=10)\n    kmeans.fit(train_features_with_chain_code)\n    labels = kmeans.predict(train_features_with_chain_code)\n    labels = encoder.fit_transform(labels.reshape(-1, 1)).toarray()\n    acc = accuracy_score(y_train, labels)\n    print('Accuracy: ', acc)\n    accuracies = np.append(accuracies, acc)\n    if max_acc < accuracies.max(): \n        max_acc = accuracies.max()\n        best = kmeans\nprint(\"max acc: \", max_acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = np.argmax(y_train, axis=1)\nlabels = np.argmax(labels, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train.shape, labels.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, labels))\ncm.plot()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using Centroid","metadata":{}},{"cell_type":"code","source":"train_features_with_centroid = np.nan_to_num(np.array([extract_features_with_centroid(image) for image in x_train]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features_with_centroid.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features_with_centroid = train_features_with_centroid.reshape(train_features_with_centroid.shape[0], -1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features_with_centroid.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"centroids, labels = k_means(train_features_with_centroid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"centroids.shape, labels.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = encoder.fit_transform(labels.reshape(-1, 1)).toarray()\ny_train = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_score(y_train, labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best = KMeans(n_clusters=10)\naccuracies = np.array([])\nmax_acc = 0\nfor _ in range(10):\n    kmeans = KMeans(n_clusters=10)\n    kmeans.fit(train_features_with_centroid)\n    labels = kmeans.predict(train_features_with_centroid)\n    labels = encoder.fit_transform(labels.reshape(-1, 1)).toarray()\n    acc = accuracy_score(y_train, labels)\n    print('Accuracy: ', acc)\n    accuracies = np.append(accuracies, acc)\n    if max_acc < accuracies.max(): \n        max_acc = accuracies.max()\n        best = kmeans\nprint(\"max acc: \", max_acc)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = np.argmax(y_train, axis=1)\nlabels = np.argmax(labels, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train.shape, labels.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_train, labels))\ncm.plot()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}